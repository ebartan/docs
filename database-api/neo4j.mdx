---
title: 'Neo4j LLM Fundamentals'
description: 'RAG (Retrieval-Augmented Generation) Chatbot Development'
---
<Warning>LLMs sometimes produce inaccurate or false information, known as "hallucinations," due to their reliance on patterns from large amounts of training data. These inaccuracies can result from overfitting, biases in the data, and the model's attempts to generalize.</Warning>

<Warning>The complexity of Large Language Models (LLMs) and their training on potentially flawed data can lead to unpredictable or inaccurate outputs. For instance, an LLM might generate biased or incorrect responses to controversial topics. Additionally, it can be challenging to trace how the model reached a particular conclusion.</Warning>

<Warning>Prompt engineering involves creating specific instructions to guide LLMs to better responses. By refining prompts, such as asking for a summary and tags instead of a vague question, developers can improve results without retraining. Adding details like response format and examples enhances output, a technique known as Zero-shot learning.</Warning>

<Warning>When writing prompts, use positive instructions for clarity. Instead of saying "Do not use complex words," specify "Use simple words, such as …​." This approach provides clearer guidance and examples, reducing ambiguity.</Warning>

<Warning>Fine-tuning adjusts a model with specific data to improve its performance on specialized tasks, like enhancing responses for a business. It requires technical expertise and substantial resources. Alternatively, you can provide relevant information directly in the prompt for simpler adjustments.</Warning>


## Conversational Agent
<Steps>
  <Step title="First Step">
    These are instructions or content that only pertain to the first step.
  </Step>
  <Step title="Second Step">
    These are instructions or content that only pertain to the second step.
  </Step>
  <Step title="Third Step">
    These are instructions or content that only pertain to the third step.
  </Step>
</Steps>